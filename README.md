# BotOrNot -- Bot Detection Pipeline

A multi-tier scoring system that identifies bot accounts in social media datasets. Built for the Bot or Not Challenge, which provides Twitter-like datasets containing a mix of human and AI-generated bot accounts.

## Competition Scoring

The challenge uses an asymmetric scoring system:

- **+4** per true positive (correctly identified bot)
- **-1** per false negative (missed bot)
- **-2** per false positive (human incorrectly flagged)

False positives cost twice as much as missed bots, so the detector is designed to require converging signals before flagging an account.

## Project Structure

```
detectorwFrench.py              Main detector with English + French support
detector.py                     Original English-only detector (legacy)
detector2.py                    Earlier iteration (legacy)
dataset.posts&users.XX.json     Input datasets (posts and user metadata)
dataset.bots.XX.txt             Ground truth bot labels (practice sets only)
BotsBeGone.detections.en.txt    Submission file -- English detections
BotsBeGone.detections.fr.txt    Submission file -- French detections
```

### Datasets

| ID  | Language | Type       | Users |
|-----|----------|------------|-------|
| 30  | English  | Practice   | 275   |
| 31  | French   | Practice   | 171   |
| 32  | English  | Practice   | 271   |
| 33  | French   | Practice   | 172   |
| 34  | English  | Submission | 438   |
| 35  | French   | Submission | 283   |

Practice datasets (30-33) include ground truth labels for evaluation. Submission datasets (34-35) are unlabeled.

## How It Works

The detector assigns each user a numerical score by running their posts through a pipeline of behavioral signals organized into three tiers. If the total score meets or exceeds the detection threshold (default: 3), the user is flagged as a bot.

### Tier 1 -- Near-Certain Signals (10 points each)

These signals have essentially zero false positive risk. Any single one is enough to confidently flag an account.

**T1a: Meta-Text / Leaked LLM Prompts.** Some bot accounts are generated by large language models that leak their instruction framing into the tweet text. Phrases like "Here are some of my recent tweets" or "Here's a revised version" never appear in real human tweets. The detector maintains a list of these phrases in both English and French. Two or more matches yield 10 points; a single match yields 2.

**T1b: Encoding Artifacts.** Certain bot generation pipelines produce text with control characters (bytes in the 0x00-0x1F range). Legitimate tweets from the Twitter API never contain these. Any occurrence yields 10 points.

### Tier 2 -- Strong Signals (2-5 points each)

These signals have low but non-zero false positive risk. They contribute significantly to the score but typically need at least one other signal to cross the threshold.

**T2a: Same-Second Tweet Bursts.** Bots that batch-post will have many tweets sharing an exact timestamp down to the second. The detector counts how many tweets share a timestamp: 5 or more duplicates yield 5 points, 3-4 yield 3 points. A corroboration rule caps the score at 2 when same-second posting is the only signal and the count is below 6, preventing thread-posting humans from being flagged.

**T2b: Posting Interval Regularity (CV).** The coefficient of variation (standard deviation divided by mean) of the time gaps between consecutive tweets. Humans post erratically with bursts and silences, producing a high CV (typically 1.8-2.0). Bots post at more regular intervals, producing a low CV (1.0-1.3). This is the single strongest statistical signal across all practice datasets. The scoring is graduated by post count:

- 10-11 posts: CV at most 1.10 yields 2 points
- 12-14 posts: CV at most 0.90 yields 4 points
- 15+ posts: full graduated scale from 5 points (CV at most 0.80) down to 2 points (CV at most 1.20)

An additional corroboration rule reduces the score for users in the marginal CV range (1.05-1.15) who have fewer than 2 @mentions, since these are more likely regular human posters.

**T2c: Template Pattern.** A class of bots generates tweets from fill-in-the-blank templates, producing pure text with zero URLs and zero hashtags. Real users who tweet 30 or more times almost always include at least some links or tags. Zero URL rate plus zero hashtag rate at 30+ posts yields 5 points.

**T2d: High "just" Frequency.** Quirky-anecdote bots generate relatable tweets that heavily overuse the word "just" ("just walked into a glass door", "just waved at someone"). Humans use "just" in roughly 5-6% of tweets; these bots hit 35-60%. At a rate of 0.35 or higher with 15+ posts, this yields 4 points. For French datasets, the detector instead looks for "viens de" / "vient de" patterns, which serve the same grammatical role.

**T2e: Zero Engagement.** Real users share links and mention other accounts. Bots that generate synthetic content into the void have zero URLs and zero @mentions across 15+ posts. This yields 2 points.

### Tier 3 -- Supporting Signals (1-2 points each)

Weak signals that provide additional evidence when combined with stronger tiers. They are never sufficient to flag an account on their own.

**T3a: Elevated Hashtag Rate.** Bots average around 0.9 hashtags per tweet compared to 0.2 for humans. A rate of 1.0 or higher yields 2 points; 0.5 or higher yields 1 point.

**T3b: Low URL Rate.** Real users share links in roughly 52% of tweets. Bots generating original text include URLs in only about 29%. A URL rate of 10% or lower at 15+ posts yields 1 point. This signal is gated on having at least one Tier 2 signal active.

**T3c: "Fun Fact" Pattern.** Quirky-anecdote bots inject the phrase "fun fact" as a filler device. Two or more occurrences yield 2 points. For French, "le saviez-vous" is matched as well.

**T3d: Repetitive Tweet Opener.** Some bots start many tweets with the same phrase, revealing a template structure. The detector checks both a list of known bot phrases (such as "remember when", "not gonna lie") and performs a dynamic first-3/4-word prefix analysis. Known phrases appearing 3 or more times yield 2 points. Dynamic openers appearing 5 or more times also yield 2 points but are gated on existing Tier 2 evidence to avoid false positives.

**T3e: Post-Length Uniformity.** Template-generated tweets tend to have consistent lengths. If the coefficient of variation of character counts is below 0.30 with at least 10 posts, this yields 1 point. Gated on having at least one Tier 2 signal.

**T3f: Human Spam Exemption.** Some accounts are human spammers (betting tips, link-sharing accounts) that post near-identical repetitive content. These are not AI bots. If sequential similarity exceeds 0.75 and vocabulary ratio is below 0.20, a large negative score (-100) is applied to ensure they are not flagged.

### Defensive Rules

Several rules prevent false positives from pure signal coincidence:

**T1/T2 Gating.** At least one Tier 1 or Tier 2 signal must fire for an account to be flagged. Tier 3 signals alone cannot cross the threshold. Exception: the combination of T3a (hashtag density >= 1) and T3d (repetitive opener >= 2) is allowed to bypass this gate, as it reliably identifies template bots even without timing-based evidence.

**Same-Second Corroboration.** When same-second bursts are the only substantial signal, the detector requires at least 6 duplicate timestamps to flag. This prevents thread-posting humans (who may have 3-5 same-second tweets from rapid thread replies) from being caught.

**CV Mention Corroboration.** Users in the marginal CV range (1.05-1.15, scoring 3 points) must have at least 2 @mentions to retain that score. Users with 0-1 mentions in this range are downgraded to 2 points, since their regular timing is more likely explained by normal posting habits.

### French-Specific Adjustments

French social media has a heavier thread-posting culture, where users post rapid-fire sequential tweets. This creates more regular timing patterns that would trigger false positives under English-calibrated thresholds. The following adjustments are applied when the dataset language is French:

**CV Thresholds.** The 10-11 post CV tier is disabled entirely (too many false positives from low-volume thread-posters). The 12-15 post tier is tightened from CV at most 0.90 to CV at most 0.80. The 16+ post graduated thresholds remain the same.

**Same-Second Ratio Rule.** When same-second posting is the only Tier 2 signal and the ratio of same-second posts to total posts is below 0.40, the score is capped at 2. Human thread-posters embed occasional threads within many regular tweets (ratio typically 0.35 or lower), while bots have a much higher same-second proportion (0.44 or higher).

**Relaxed Spam Exemption.** French human spammers produce slightly more varied content that does not meet the strict English thresholds. The spam exemption thresholds for French are relaxed to sequential similarity above 0.60 and vocabulary ratio below 0.30.

**Multi-T3 Gating Bypass.** The combination of high hashtag density (T3a >= 1) and repetitive openers (T3d >= 2) is allowed to flag without Tier 1 or Tier 2 support. This catches French bots that have human-like timing but clear content-level bot signatures.

## Usage

Run the detector on all practice datasets:

```
python detectorwFrench.py all
```

Run on a specific dataset by alias:

```
python detectorwFrench.py 30
python detectorwFrench.py 35
```

Generate a submission file:

```
python detectorwFrench.py 34 -o BotsBeGone.detections.en.txt
python detectorwFrench.py 35 -o BotsBeGone.detections.fr.txt
```

Enable verbose output to see per-user scoring:

```
python detectorwFrench.py 30 --verbose
```

Set a custom detection threshold:

```
python detectorwFrench.py all --threshold 4
```

## Results on Practice Data

| Dataset | Language | TP  | FP | FN | Score     | Max  | Pct  |
|---------|----------|-----|----|----|-----------|------|------|
| 30      | English  | 64  | 2  | 2  | +250      | 264  | 95%  |
| 31      | French   | 24  | 3  | 3  | +86       | 108  | 80%  |
| 32      | English  | 59  | 2  | 4  | +228      | 252  | 90%  |
| 33      | French   | 27  | 4  | 1  | +99       | 112  | 88%  |
| **All** | **Both** |**174**|**11**|**10**|**+663**|**736**|**90%**|

English combined: +478 / 516 (93%). French combined: +185 / 220 (84%).

## Dependencies

Python 3.10+ with only standard library modules (json, re, statistics, argparse, collections, datetime, pathlib, difflib). No external packages required.
